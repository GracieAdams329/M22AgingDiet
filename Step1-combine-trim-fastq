#COMBINE FASTQ FILES FOR EACH BARCODE
#In fastq_pass
ls >> barcodelist.txt
#nano to edit and remove the ‘barcodelist.txt’ line at the bottom of the file
barclist=$(cat barcodelist.txt)

#Change to the first library folder
cd /fastdata/bop23ga/FOLDER/FLOWCELLLIBRARYX/

#Unzip and merge fastq files for each barcode into one file
for g in ${barclist[@]}
do
cd ${g}
gunzip *.fastq.gz
cat *.fastq > /fastdata/bop23ga/FOLDER/fastq_pass/${g}_merge.fastq
cd /fastdata/bop23ga/FOLDER/fastq_pass/
done

#BARCODE TRIMMING
#In fastq_pass
ls >> barcodelist.txt
#nano to edit and remove the ‘barcodelist.txt’ line at the top/bottom of the file and '_merge.fastq' from the end of each line
barclist=$(cat barcodelist.txt)

for g in ${barclist[@]}
do /usr/local/extras/Genomics/apps/dorado/dorado-0.8.1-linux-x64/bin/dorado trim ${g}_merge.fastq > ${g}_merge_trimmed.fastq --emit-fastq
done
#Dorado default emits a bam file with more data but then this can’t be used by minimap2.

To submit as a script to run faster:
-------
#!/bin/bash
# Request 8 gigabytes of real memory (RAM) 2 cores *4G = 8
#SBATCH --mem=8G
# Request 2 cores
#SBATCH --cpus-per-task=2
# Email notifications
#SBATCH --mail-user=gadams3@sheffield.ac.uk
# Email notifications
#SBATCH --mail-type=ALL
# Change job output log file name (default is slurmJOBID)
#SBATCH --output=output.DoradotrimDATE.out
# Request more time (default is 8 hours)
#SBATCH --time=24:00:00

#Activate the repository
#echo -e "if [[ -e '/usr/local/extras/Genomics' ]];\nthen\n\tsource /usr/local/extras/Genomics/.bashrc\nfi" >> $HOME/.bash_profile
source /usr/local/extras/Genomics/.bashrc

# Set the OPENMP_NUM_THREADS environment variable to 4
# This is needed to ensure efficient core usage.
export OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK

cd /fastdata/bop23ga/FOLDER/fastq_pass/
barclist=$(cat barcodelist.txt)

for g in ${barclist[@]}
do /usr/local/extras/Genomics/apps/dorado/dorado-0.8.1-linux-x64/bin/dorado trim ${g}_merge.fastq > ${g}_merge_trimmed.fastq --emit-fastq
done
